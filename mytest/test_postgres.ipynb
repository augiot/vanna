{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install 'vanna[chromadb,postgres]'\n",
    "# %pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "project_dir = '/mnt/user2/workspace/Aug/code/Chat/exp/vanna/'\n",
    "# 将父级目录的父级目录添加到系统路径中\n",
    "sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vanna.base import VannaBase\n",
    "from src.vanna.chromadb.chromadb_vector import ChromaDB_VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomLLM(VannaBase):\n",
    "    def __init__(self, config=None):\n",
    "        pass\n",
    "\n",
    "    def generate_plotly_code(self, question: str = None, sql: str = None, df_metadata: str = None, **kwargs) -> str:\n",
    "        # Implement here\n",
    "        pass    \n",
    "\n",
    "    def generate_question(self, sql: str, **kwargs) -> str:\n",
    "        # Implement here\n",
    "        pass\n",
    "        \n",
    "    def get_followup_questions_prompt(self, question: str, question_sql_list: list, ddl_list: list, doc_list: list, **kwargs):\n",
    "        # Implement here\n",
    "        pass\n",
    "    \n",
    "    def get_sql_prompt(self, question: str, question_sql_list: list, ddl_list: list, doc_list: list, **kwargs):\n",
    "        # Implement here\n",
    "        pass\n",
    "\n",
    "    def submit_prompt(self, prompt, **kwargs) -> str:\n",
    "        # Implement here\n",
    "        pass\n",
    "            \n",
    "\n",
    "class MyVanna(ChromaDB_VectorStore, MyCustomLLM):\n",
    "    def __init__(self, config=None):\n",
    "        ChromaDB_VectorStore.__init__(self, config=config)\n",
    "        MyCustomLLM.__init__(self, config=config)\n",
    "\n",
    "vn = MyVanna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vanna.openai.openai_chat import OpenAI_Chat\n",
    "class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):\n",
    "    def __init__(self, config=None):\n",
    "        ChromaDB_VectorStore.__init__(self, config=config)\n",
    "        OpenAI_Chat.__init__(self, config=config)\n",
    "\n",
    "vn = MyVanna(config={'api_key': 'sk-...', 'model': 'gpt-4-...'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vanna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
